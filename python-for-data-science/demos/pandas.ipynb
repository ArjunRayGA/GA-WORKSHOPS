{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it's easier calling submodules of pandas using pd. less typing! plus using pd is standard\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas DataFrames\n",
    "A [`pandas.Dataframe`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) is a specialized 2-d data type with column labels, much like a spreadsheet. DataFrames are the core data type of the pandas package.  \n",
    "A dataframe has row labels, column labels, and values in each \"cell\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_l = ['me', 'you', 'him', 'her']\n",
    "col_l = ['height', 'weight', 'eyecolor']\n",
    "x = [[68, 155, 'brown'], [56, 200, 'blue'], [70, 170, 'black'], [50, 130, 'brown']]\n",
    "\n",
    "simple_df = pd.DataFrame(data=x, index=row_l, columns=col_l)\n",
    "print(simple_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to make a DataFrame is with a dict as the argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'name': ['Sandra', 'Rajitha', 'John'], 'height': [54, 46, 70]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notice how we don't need to `print` something if it's the last command that returns a value?* \n",
    "\n",
    "Anyway, back to our `simple_df`. Normally, you leave index empty and pandas assigned values automatically from 0 to n for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_l = ['person'] + col_l # add 'person label to beginning of columns'\n",
    "\n",
    "for i, row in enumerate(x):  # add person values previously in row_l to x\n",
    "    x[i] = [row_l[i]] + row\n",
    "\n",
    "print('\\nCOL_L')\n",
    "print(col_l)\n",
    "print('\\nX')\n",
    "print(x)\n",
    "\n",
    "simple_df = pd.DataFrame(data=x, columns=col_l) # notice how we did not use index arg this time\n",
    "\n",
    "print('\\nSIMPLE_DF')\n",
    "print(simple_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas automatically guesses the variable type for each column. each column can only have one var type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the data types of each columne\n",
    "print(simple_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating DataFrames\n",
    "You can select the values within a DataFrame column. pandas returns another type of data structure called a Series. Each column in a DataFrame is a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heights = simple_df['height']\n",
    "print(heights)\n",
    "print\n",
    "print(type(heights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily transpose your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(simple_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas supports a DataFrame manipulation pattern called 'slicing' for selecting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(simple_df[:])  # selects all rows (rows are the first dimension)\n",
    "print\n",
    "print(simple_df[:3]) # selects the rows from start up to but not including row 3 ( same as [0:3] slice)\n",
    "print\n",
    "print(simple_df[1:2]) # selects rows 1 up to and not including row 2 (ie, just row 1)\n",
    "print\n",
    "print(simple_df[::2]) # selects every 2nd row (0 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can join values to a pandas dataframe along the row axis (0) or column axis (1)\n",
    "\n",
    "print(\"\\nJOINED ON AXIS=0\")\n",
    "print(pd.concat([simple_df, simple_df])) # axis=0 by default when no argument is passed\n",
    "print(\"\\nJOINED ON AXIS=1\")\n",
    "print(pd.concat([simple_df, simple_df], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use boolean logic to get parts of a DataFrame. What if we wanted to get a DataFrame back with only the brown eyed people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when you select a row by name and test its' value, you get back a boolean for each element in that row\n",
    "is_brown_eyed = simple_df['eyecolor'] == 'brown'\n",
    "print(is_brown_eyed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_df[is_brown_eyed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing csv files as DataFrames\n",
    "Remember how I mentioned that DataFrames are very much like Excel sheets? We can in fact import csvs and even Excel files into python as DataFrames.\n",
    "\n",
    "Now, let's import some real data froma a csv using [`pandas.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). We've got a csv file at in our `assets/datasets` folder called `titanic.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../assets/datasets/titanic.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should look at our data set columns and maybe some of the data bu we probably don't want to print all 891 lines of our DataFrame. How do we preview it? We can use `pandas.DataFrame.head` and `pandas.DataFrame.tail` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prints the first lines of the DataFrame. can take an int as an argument for number of lines, 5 by default\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.tail prints from the end in the same way\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are a lot of `NaN` (not a number) values in our cabin column. Let's get rid of any rows\n",
    "that have NaN in them using [`pandas.DataFrame.dropna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df = df.dropna()\n",
    "\n",
    "print(len(clean_df), len(df)) # let's see how many rows were dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes. we lost over 700 rows! Is ther another way to get rid of the `NaN` values? Yes there is! We can fill them in with [`pandas.DataFrame.fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filled_df = df.fillna(method='backfill')\n",
    "\n",
    "print(len(filled_df), len(df)) # let's see how many rows were dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK we kept all of our rows! But what did `method='backfill'` do? Let's look at the docs..\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, let's forget about cabin. In fact, let's get rid of some other unintersting columns too. Let's drop `name`, `sibsp`, `ticket`, `fare`, `cabin`, and `embarked` using [`pandas.DataFrame.drop`](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = filled_df # let's get our filled in values into our previously named df DataFrame\n",
    "df = df.drop(labels=['name','sibsp', 'ticket', 'fare', 'cabin', 'embarked'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes for a categorical variable with more than 2 levels, you want a simply boolean/binary value for whether a data point belongs to a level or not. In orde to do this, we can use [`pd.get_dummies`](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.get_dummies.html) to create what are called dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['pclass'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lastly, let's get some summary data on our titanic data. Let's figure out how many people survived of each gender\n",
    "using [`pandas.DataFrame.groupby`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just running groupby returns a pandas.core.groupby.DataFrameGroupBy object\n",
    "# in order to get data out of it, you have to do something with the groups sum as 'count', 'mean', etc\n",
    "df.groupby(['sex']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get just the number of survivors in our groupby table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['sex']).count()['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can easily get descriptive statistics about our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Pandas Cookbook](https://github.com/jvns/pandas-cookbook#how-to-use-this-cookbook) - an excellent resource for getting further into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
